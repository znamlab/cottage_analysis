{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye fitting from Damian et al 2013.\n",
    "\n",
    "From this paper: https://www.nature.com/articles/nature12153\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import flexiznam as flz\n",
    "from skimage.measure import EllipseModel\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from cottage_analysis.utilities.plot_utils import get_img_from_fig, write_fig_to_video\n",
    "from cottage_analysis.eye_tracking import eye_model_fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"blota_onix_pilote\"\n",
    "mouse = \"BRAC6692.4a\"\n",
    "session = \"S20221216\"\n",
    "recording = \"Arena_dark_floor\"\n",
    "camera = \"eye_camera\"\n",
    "video_time = \"2022-12-16T11_26_01\"\n",
    "\n",
    "raw = Path(flz.PARAMETERS[\"data_root\"][\"raw\"])\n",
    "processed = Path(flz.PARAMETERS[\"data_root\"][\"processed\"])\n",
    "\n",
    "data_folder = raw / project / mouse / session / recording / camera\n",
    "raw_video_file = data_folder / f\"{camera}_{video_time}.mp4\"\n",
    "video_timestamps = data_folder / f\"{camera}_timestamps_{video_time}.csv\"\n",
    "video_metadata = data_folder / f\"{camera}_metadata_{video_time}.yml\"\n",
    "\n",
    "assert all([f.exists() for f in (raw_video_file, video_timestamps, video_metadata)])\n",
    "\n",
    "data_folder = processed / project / mouse / session / recording / camera\n",
    "video_file = data_folder / f\"{camera}_{video_time}_cropped.mp4\"\n",
    "assert video_file.exists()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of specular highlights\n",
    "\n",
    "Make binary masks to remove reflection of IR light\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example frame\n",
    "\n",
    "frame_id = 24649\n",
    "\n",
    "cam_data = cv2.VideoCapture(str(video_file))\n",
    "cam_data.set(cv2.CAP_PROP_POS_FRAMES, frame_id - 1)\n",
    "ret, frame = cam_data.read()\n",
    "cam_data.release()\n",
    "\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot(1, 1, 1, aspect=\"equal\")\n",
    "ax.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for translation\n",
    "\n",
    "A simpler filter to find eye translation. It is called $B_1$ in the paper and is simply a threshold:\n",
    "\n",
    "$B_1 = I_{eye} \\circ G > median(I_{eye}).\\lambda _1$\n",
    "\n",
    "Where $G$ is a gaussian filter (15x15 in their case) and $\\lambda_1$ a user defined parameters (default to 2.5 in their case).\n",
    "\n",
    "$B_2$ is $B_1$ with a morphological opening and closing and the final filter is:\n",
    "\n",
    "$B_L = \\neg (B_1 \\land B_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda1 = 1.5\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "blurr = cv2.GaussianBlur(gray, (5, 5), 5)\n",
    "B1 = (blurr > np.nanmedian(gray) * lambda1).astype(\"uint8\")\n",
    "\n",
    "# Open and close once to remove speckles\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "B2 = cv2.morphologyEx(B1.astype(\"uint8\"), cv2.MORPH_CLOSE, kernel)\n",
    "B2 = cv2.morphologyEx(B2, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "Bl = ~(B1 & B2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5)\n",
    "fig.set_size_inches(10, 3)\n",
    "axes[0].imshow(gray)\n",
    "axes[1].imshow(blurr)\n",
    "axes[2].imshow(B1)\n",
    "axes[3].imshow(B2)\n",
    "axes[4].imshow(Bl)\n",
    "\n",
    "for i, t in enumerate([\"Raw\", \"Blurred\", \"B1\", \"B2\", \"Bl\"]):\n",
    "    axes.flatten()[i].set_title(t)\n",
    "    axes.flatten()[i].set_xticks([])\n",
    "    axes.flatten()[i].set_yticks([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter for pupil\n",
    "\n",
    "It uses some ad-hoc filters, $F_x$ and $F_y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct filters\n",
    "H = np.ones([5, 5])\n",
    "for corner in [(0, 0), (0, -1), (-1, 0), (-1, -1)]:\n",
    "    H[corner[0], corner[1]] = 0\n",
    "print(\"H:\")\n",
    "print(H)\n",
    "\n",
    "v = np.array([[-0.343, -0.171, 0, 0.171, 0.343]])\n",
    "Fy = np.tile(v.T, 5) * H\n",
    "print(\"Fy:\")\n",
    "print(Fy)\n",
    "Fx = Fy.T\n",
    "\n",
    "print(\"Fx:\")\n",
    "print(Fx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurr_radius = 5\n",
    "blurr = cv2.GaussianBlur(gray, (blurr_radius, blurr_radius), blurr_radius)\n",
    "Ix = cv2.filter2D(blurr, -1, Fx)\n",
    "Iy = cv2.filter2D(blurr, -1, Fy)\n",
    "Idelta = Ix**2 + Iy**2\n",
    "\n",
    "lambda2 = 1.5\n",
    "lambda3 = 2.5\n",
    "B3_low = blurr > np.median(gray) * lambda2\n",
    "B3_high = Idelta < np.median(Idelta) * lambda3**2\n",
    "B3 = B3_low | B3_high\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "B4 = cv2.morphologyEx(B3.astype(\"uint8\"), cv2.MORPH_CLOSE, kernel)\n",
    "B4 = cv2.morphologyEx(B4.astype(\"uint8\"), cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "Bp = ~(B3 | B4)\n",
    "\n",
    "img_list = [Ix, Iy, Idelta, B3_low, B3_high, B3, B4, Bp]\n",
    "titles = [\"Ix\", \"Iy\", r\"$I_{\\delta}$\", \"B3 low\", \"B3 hight\", \"B3\", \"B4\", \"B_p\"]\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "for i, (ax, img) in enumerate(zip(axes.flatten(), img_list)):\n",
    "    ax.imshow(img_list[i].astype(\"uint8\"))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurr_radius = 7\n",
    "blurr = cv2.GaussianBlur(gray, (blurr_radius, blurr_radius), blurr_radius)\n",
    "Ix = cv2.filter2D(blurr, -1, Fx)\n",
    "Iy = cv2.filter2D(blurr, -1, Fy)\n",
    "Idelta = Ix**2 + Iy**2\n",
    "\n",
    "lambda2 = 1.5\n",
    "lambda3 = 3.5\n",
    "B3_low = blurr > np.median(gray) * lambda2\n",
    "B3_high = Idelta < np.median(Idelta) * lambda3**2\n",
    "B3 = B3_low | B3_high\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "B4 = cv2.morphologyEx()\n",
    "img_list = [Ix, Iy, Idelta, B3_low, B3_high, B3]\n",
    "titles = [\"Ix\", \"Iy\", r\"$I_{\\delta}$\", \"B3 low\", \"B3 hight\", \"B3\"]\n",
    "fig, axes = plt.subplots(3, 3)\n",
    "for i, (ax, img) in enumerate(zip(axes.flatten(), img_list)):\n",
    "    ax.imshow(img_list[i].astype(\"uint8\"))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(titles[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "272882de78d91b881035f683a12ffa07edc574ccc635c980b383a6ea3db59afc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
