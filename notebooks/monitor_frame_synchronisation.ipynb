{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37d7cce3",
   "metadata": {},
   "source": [
    "# Visual stimulation monitor synchronisation\n",
    "\n",
    "Bonsai controls visual display and saves a log everytime it asks for a frame to be rendered. However there is an unknown delay (~2 frames) between this render frame event and the actual display time. Furthermore some frames are skipped.\n",
    "\n",
    "To figure out which frame is displayed when we put a photodiode in front of the monitor and display a pseudo-random sequence of alternating grey value. \n",
    "\n",
    "This notebook show how we use the frame logger and the photodiode signal to determine exact frame identity at each point of time. It has 3 main steps\n",
    "\n",
    "**1. Detect frames on photodiode signal**\n",
    "\n",
    "**2. Cross-correlate frame with sequence to find expected lag**\n",
    "\n",
    "**3. Match cross correlation results to frame logger**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64fe5d3",
   "metadata": {},
   "source": [
    "\n",
    "### Load example data\n",
    "\n",
    "This next section just loads one example recording to be used for the rest of the notebook.\n",
    "\n",
    "Define the session we want:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90e896",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'hey2_3d-vision_foodres_20220101'\n",
    "MOUSE = 'PZAH8.2f'\n",
    "SESSION = 'S20230126'\n",
    "RECORDING = 'R144331_SpheresPermTubeReward'\n",
    "PROTOCOL = 'SpheresPermTubeReward'\n",
    "MESSAGES = 'harpmessage.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf24fdb",
   "metadata": {},
   "source": [
    "Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2857981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import flexiznam as flm\n",
    "from cottage_analysis.io_module import harp\n",
    "\n",
    "data_root = flm.PARAMETERS[\"data_root\"]\n",
    "msg = Path(data_root[\"raw\"]) / PROJECT / MOUSE / SESSION / RECORDING / MESSAGES\n",
    "p_msg = Path(data_root[\"processed\"]) / PROJECT / MOUSE / SESSION / RECORDING / (PROTOCOL+'_suite2p_traces_0')\n",
    "p_msg = p_msg / (msg.stem + \".npz\")\n",
    "if p_msg.is_file():\n",
    "    harp_message = np.load(p_msg)\n",
    "else:\n",
    "    harp_message = harp.load_harp(\n",
    "        msg, di_names=('frame_triggers','lick_detection','di2_encoder_initial_state')\n",
    "    )\n",
    "    p_msg.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez(p_msg, **harp_message)\n",
    "\n",
    "frame_log = pd.read_csv(msg.parent / \"FrameLog.csv\")\n",
    "expected_sequence = (\n",
    "    pd.read_csv(msg.parent / 'random_sequence_5values_alternate.csv', header=None).loc[:, 0].values\n",
    ")\n",
    "step_values = frame_log.PhotoQuadColor.unique()\n",
    "ao_time = harp_message[\"analog_time\"]\n",
    "photodiode = harp_message[\"photodiode\"]\n",
    "ao_sampling = 1 / np.mean(np.diff(ao_time))\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "print(\n",
    "    \"Recording is %d s long.\"\n",
    "    % (frame_log.HarpTime.values[-1] - frame_log.HarpTime.values[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae8f2f",
   "metadata": {},
   "source": [
    "# Normal usage\n",
    "\n",
    "This is using the main master function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.preprocessing import find_frames\n",
    "\n",
    "frame_rate = 144\n",
    "frames_df, db_dict = find_frames.sync_by_correlation(\n",
    "    frame_log,\n",
    "    ao_time,\n",
    "    photodiode,\n",
    "    time_column=\"HarpTime\",\n",
    "    sequence_column=\"PhotoQuadColor\",\n",
    "    num_frame_to_corr=6,\n",
    "    maxlag=3.0 / frame_rate,\n",
    "    expected_lag=2.0 / frame_rate,\n",
    "    frame_rate=frame_rate,\n",
    "    correlation_threshold=0.8,\n",
    "    relative_corr_thres=0.02,\n",
    "    minimum_lag=1.0 / frame_rate,\n",
    "    do_plot=False,\n",
    "    verbose=True,\n",
    "    debug=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5395351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "save_folder = Path(data_root[\"processed\"]) / PROJECT / MOUSE / SESSION / RECORDING / (PROTOCOL+'_suite2p_traces_0')\n",
    "\n",
    "frames_df.to_pickle(save_folder/'frames_df.pickle')  \n",
    "with open(save_folder/'db_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(db_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_folder/'db_dict.pickle', 'rb') as handle:\n",
    "    db_dict = pickle.load(handle)\n",
    "with open(save_folder/'frames_df.pickle', 'rb') as handle:\n",
    "    frames_df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927613ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da90afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df.sync_reason.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e05db",
   "metadata": {},
   "source": [
    "# Detailled description\n",
    "\n",
    "How does it work? The alignment is made in 3 steps:\n",
    "\n",
    "- detect frames\n",
    "- crosscorrelated with expected sequence\n",
    "- align results\n",
    "\n",
    "## Detect frames\n",
    "\n",
    "The frame detection is simple: filter a bit to smooth local extrema, `diff` to find fast changes and detect peaks on that `diff` trace. This should detect all frame borders. In between these borders, look for the `diff` minimum to find the frame peak (be it a maximum or a minium)\n",
    "\n",
    "Detection can be done independently using `detect_frame_onset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sampling = 1 / np.mean(np.diff(ao_time))\n",
    "out = find_frames.detect_frame_onset(\n",
    "    photodiode=photodiode,\n",
    "    frame_rate=frame_rate,\n",
    "    photodiode_sampling=pd_sampling,\n",
    "    highcut=frame_rate * 3,\n",
    "    debug=True,\n",
    ")\n",
    "frame_borders, peak_index, db_dict = out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e02230",
   "metadata": {},
   "source": [
    "You can get an example of detection using `plot_frame_detection_report`. This will give you `num_examples * 2` figures. Half of them are selected on random frames, half are centered around a frame drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc9fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_window = np.array([-7.5, 7.5]) / frame_rate * pd_sampling\n",
    "figs = find_frames.plot_frame_detection_report(\n",
    "    border_index=frame_borders,\n",
    "    peak_index=peak_index,\n",
    "    debug_dict=db_dict,\n",
    "    num_examples=1,\n",
    "    plot_window=plot_window,\n",
    "    photodiode=photodiode,\n",
    "    frame_rate=frame_rate,\n",
    "    photodiode_sampling=pd_sampling,\n",
    "    highcut=frame_rate * 3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e4728",
   "metadata": {},
   "source": [
    "## Crosscorrelation\n",
    "\n",
    "After having detected frames we will try to find where each of them falls in the photodiode sequence. To do that, we start by normalising the photodiode signal between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_pd = np.array(photodiode, dtype=float)\n",
    "normed_pd -= np.quantile(normed_pd, 0.01)\n",
    "normed_pd /= np.quantile(normed_pd, 0.99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54044fba",
   "metadata": {},
   "source": [
    "### Idealised photodiode\n",
    "\n",
    "Then we generate an idealised version of what the photodiode signal should be (had their been no frame drops)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b32dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_trace, ideal_pd = find_frames.ideal_photodiode(time_base=ao_time,\n",
    "                                switch_time=frame_log['HarpTime'].values,\n",
    "                                sequence=frame_log['PhotoQuadColor'].values)\n",
    "\n",
    "fig = plt.figure()\n",
    "w = np.array([10000, 10100])\n",
    "t0 = ao_time[w[0]]\n",
    "plt.plot(ao_time[slice(*w)] - t0, normed_pd[slice(*w)], label='Normed photodiode')\n",
    "plt.plot(ao_time[slice(*w)] - t0, seq_trace[slice(*w)], label='Sequence',\n",
    "         color='grey', alpha=0.5)\n",
    "plt.plot(ao_time[slice(*w)] - t0, ideal_pd[slice(*w)], label='Filtered sequence')\n",
    "l = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75593f0d",
   "metadata": {},
   "source": [
    "### Data chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13059ae",
   "metadata": {},
   "source": [
    "Now we want to run the crosscorrelation around each frame.\n",
    "\n",
    "We need to take a chunk of data that is big enough but short enough. Five or 6 frames seems to get good unique match with the sequence. Use `num_frame_to_corr` to set that.\n",
    "\n",
    "Then we need to shift the photodiode by a given lag and cut the same chunk of data to correlate. There is no point in testing all the shifts, we now it will be about 2 frames. So we have `expected_lag ~= int(2/frame_rate*ao_sampling)` (in samples). \n",
    "\n",
    "To make things reasonably fast we also limit the search to a 3 frames of lag (+/- around expected_lag). With `maxlag ~= int(3/frame_rate*ao_sampling)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frame_to_corr = 6\n",
    "maxlag_samples = int(np.round(3 / frame_rate * ao_sampling))  # make it into samples\n",
    "expected_lag_samples = int(np.round(2 /frame_rate * ao_sampling))  # make it into samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5db73bc",
   "metadata": {},
   "source": [
    "Finally we need to decide if we take the chunk of data before the frame, centered on the frame or after the frame. The best choice depends on if there was a frame drop recently or not. So let's just do the 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79721b",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = [np.array([-1, 1]) * maxlag_samples + \n",
    "          np.array(w * num_frame_to_corr / frame_rate\n",
    "                    * ao_sampling, dtype='int')\n",
    "              for w in [np.array([-1, 0]), np.array([-0.5, 0.5]), np.array([0, 1])]]\n",
    "# for bef window, we add 1 frame to have the current frame included\n",
    "window[0] += int(1/frame_rate * ao_sampling)\n",
    "# for center window, we shift by 0.5 frame to center\n",
    "window[1] += int(0.5/frame_rate * ao_sampling)\n",
    "\n",
    "example_frame = 5234\n",
    "frame_sample = frame_borders[example_frame]\n",
    "lab = ['bef', 'center', 'aft']\n",
    "t0 = ao_time[frame_sample]\n",
    "for iw, w in enumerate(window):\n",
    "    part = slice(*w + frame_sample)\n",
    "    plt.plot(ao_time[part][maxlag_samples:-maxlag_samples+1] - t0, \n",
    "             normed_pd[part][maxlag_samples:-maxlag_samples+1] + iw * 0.5, \n",
    "             label=lab[iw])\n",
    "plt.axvspan(ao_time[frame_sample] - t0, ao_time[frame_borders[example_frame + 1]] - t0, \n",
    "            alpha=0.5)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5771c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlag_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d53e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_=plt.hist(frames_df.lag.values*1000, \n",
    "           bins=np.arange(frames_df.lag.min()*1000,frames_df.lag.max()*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb39769",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = np.diff(frames_df.closest_frame.values) < 1\n",
    "frames_df.iloc[1:][bad]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bca33c3",
   "metadata": {},
   "source": [
    "Add that to the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dad53a",
   "metadata": {},
   "source": [
    "## Match cross correlation results to frame logger\n",
    "\n",
    "Ideally, if there is no frame drop, it does not matter if we look at the frames perceeding or following the frame we want to sync. That should be most of the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66934d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db_dict['debug_info']\n",
    "normed_pd = np.array(photodiode, dtype=float)\n",
    "normed_pd -= np.quantile(normed_pd, 0.01)\n",
    "normed_pd /= np.quantile(normed_pd, 0.99)\n",
    "db.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2de6eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(102)\n",
    "w = frames_df[frames_df.sync_reason == 'photodiode matching'].index\n",
    "random_select = [w[i] for i in rng.integers(len(w), size=10)]\n",
    "bad = np.diff(frames_df.closest_frame.values) < 1\n",
    "badi = np.where(bad)[0]\n",
    "random_select = frames_df.iloc[badi[20]+np.array([0, 1, 2], dtype=int)].index\n",
    "labels = ['bef', 'center', 'aft']\n",
    "num_frame_to_corr=5\n",
    "maxlag=int(5./frame_rate*ao_sampling)\n",
    "expected_lag=int(2./frame_rate*ao_sampling)\n",
    "window = [np.array([-1, 1]) * maxlag + \n",
    "          np.array(w * num_frame_to_corr/frame_rate * ao_sampling, dtype='int')\n",
    "          for w in [np.array([-1,0]), np.array([-0.5, 0.5]), np.array([0, 1])]]\n",
    "seq_trace = db['seq_trace']\n",
    "\n",
    "for frame in random_select:\n",
    "    #frame = frames_df[~good].index[num]\n",
    "    #frame = frames_df.index[num]\n",
    "    fseries = frames_df.loc[frame]\n",
    "    on_s = fseries.onset_sample\n",
    "    off_s = fseries.offset_sample\n",
    "    on_t = fseries.onset_time\n",
    "    off_t = fseries.offset_time\n",
    "    w = np.array([-50, 50])\n",
    "    vfdf = frames_df[(frames_df.onset_sample > w[0] + on_s) &\n",
    "                     (frames_df.offset_sample < w[1] + off_s)]\n",
    "    qc = np.array([fseries[['quadcolor_%s' % w for w in labels]]])\n",
    "    best = fseries.crosscorr_picked\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    plt.gca().get_yaxis().set_visible(False)\n",
    "\n",
    "    col = dict(bef='r', center='g', aft='b')\n",
    "    for i in range(3):\n",
    "        label = 'Photodiode' if i == 1 else None\n",
    "        plt.plot(ao_time[slice(*w+on_s)]-on_t, normed_pd[slice(*w+on_s)] + i,\n",
    "                 label=label, color='purple')\n",
    "        label = 'Frame #%d' % frame if i == 1 else None\n",
    "        plt.axvspan(0, off_t-on_t, color='purple', alpha=0.2, label=label)\n",
    "        plt.plot(fseries.peak_time - on_t, fseries.photodiode, 'o', color='purple')\n",
    "\n",
    "\n",
    "    vlog = frame_log[(frame_log.HarpTime > w[0] / ao_sampling + on_t - fseries.lag_bef) &\n",
    "                     (frame_log.HarpTime < w[1] / ao_sampling + off_t)]\n",
    "    plt.plot(vlog.HarpTime.values - on_t, vlog.PhotoQuadColor - 1.5, drawstyle='steps-post', \n",
    "             label='Render frame')\n",
    "\n",
    "    i = 0\n",
    "    for win, lab in zip(window, ['bef', 'center', 'aft']):\n",
    "        cut_win = win + maxlag * np.array([1,-1], dtype=int)\n",
    "        l = fseries['lag_%s' % lab]\n",
    "        part = seq_trace[slice(*win + on_s)]\n",
    "        cut_part = seq_trace[slice(*cut_win + on_s)]\n",
    "        x = normed_pd[slice(*win+on_s)][maxlag :-maxlag + 1]\n",
    "        \n",
    "        plt.plot(ao_time[slice(*win+on_s)]-on_t + l, part + i, alpha=0.75, lw=2,\n",
    "                color=col[lab])\n",
    "        plt.plot(ao_time[slice(*win+on_s)][maxlag :-maxlag + 1] -on_t,\n",
    "                 x + i, alpha=0.5, lw=4, ls='--', color=col[lab])\n",
    "        \n",
    "        cl = fseries['closest_frame_%s'% lab]\n",
    "        plt.plot(frame_log.iloc[cl].HarpTime - on_t, frame_log.iloc[cl].PhotoQuadColor-1.5 + i/6, 'o',\n",
    "                color=col[lab])\n",
    "        if lab == best:\n",
    "            plt.plot(frame_log.iloc[cl].HarpTime - on_t, frame_log.iloc[cl].PhotoQuadColor-1.5 + i/6, 'o',\n",
    "                    mfc='None', mec='k', ms=10, mew=2)\n",
    "            plt.plot(frame_log.iloc[cl].HarpTime - on_t + l, frame_log.iloc[cl].PhotoQuadColor + i, 'o',\n",
    "                    color='k')\n",
    "            plt.plot(ao_time[slice(*cut_win+on_s)]-on_t + l, cut_part + i, alpha=1, lw=1,\n",
    "                     color='k', label='Selected match')\n",
    "\n",
    "        i+=1\n",
    "        plt.title('%s' % fseries.onset_sample)\n",
    "\n",
    "    plt.legend(loc='lower right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4230d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77caab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find what is the actual photodiode value and how does it depend on previous value\n",
    "\n",
    "df = pd.DataFrame(frames_df.iloc[1:][['quadcolor', 'photodiode']]).reset_index()\n",
    "bef = pd.DataFrame(frames_df.iloc[:-1][['quadcolor', 'photodiode']]).reset_index()\n",
    "df['quadcolor_before'] = bef['quadcolor']\n",
    "df['photodiode_before'] = bef['photodiode']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1af8ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_data = df.groupby(['quadcolor_before', 'quadcolor']).aggregate(np.nanmean).photodiode\n",
    "n_data = df.groupby(['quadcolor_before', 'quadcolor']).aggregate(len).photodiode\n",
    "m = mat_data.values.reshape((5, 5))\n",
    "n = n_data.values.reshape((5, 5))\n",
    "plt.figure(figsize=(12,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(m.T, origin='lower')\n",
    "cm = plt.colorbar()\n",
    "plt.xlabel('quad n-1')\n",
    "plt.ylabel('quad n')\n",
    "plt.title('Photodiode')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Difference')\n",
    "plt.imshow((m-np.linspace(0,1,5)).T, origin='lower', cmap='RdBu_r')\n",
    "plt.xlabel('quad n-1')\n",
    "plt.ylabel('quad n')\n",
    "cm = plt.colorbar()\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('N transitions')\n",
    "plt.imshow(n.T, origin='lower')\n",
    "plt.xlabel('quad n-1')\n",
    "plt.ylabel('quad n')\n",
    "cm = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70e6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac69145",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d09668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7beb44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c1be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742d37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7864b0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda39a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9fd0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362fd146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f489290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebacb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313ba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff837f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd1199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8f89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fseries = frames_df.loc[4713]\n",
    "fseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = fseries.offset_time\n",
    "frame_log['HarpTime'][1940:1955] - fseries.lag_aft - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b43e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_df.sync_reason.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ac6fb",
   "metadata": {},
   "source": [
    "# Divers stuff\n",
    "\n",
    "Figures to explain things for my lab meeting (09/11/2022)\n",
    "\n",
    "## Sequence principle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9908abfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "b = 1000\n",
    "w = 100\n",
    "shift = 1\n",
    "0\n",
    "seq = seq_trace[b:b+w]\n",
    "bad_seq = np.array(seq_trace[b+shift: b+w+shift])\n",
    "bad_seq[int(w/3):int(w/3 + w/3 * 0.6)] = bad_seq[int(w/3)]\n",
    "ax.plot((ao_time[b:b+w] - ao_time[b])*1e3, bad_seq)\n",
    "ax.plot((ao_time[b:b+w] - ao_time[b])*1e3, seq + 1)\n",
    "ax.set_xlabel('Time (ms)')\n",
    "ax.yaxis.set_visible(False)\n",
    "for w in ['top', 'left', 'right']:\n",
    "    ax.spines[w].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2p_analysis_cottage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "939011bda4ac240316e77cd9a4c8c2e7aac31e833bb6d639fcef3c3405a9852b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
