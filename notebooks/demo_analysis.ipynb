{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import functools\n",
    "\n",
    "print = functools.partial(print, flush=True)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import flexiznam as flz\n",
    "from cottage_analysis.io_module import harp\n",
    "from cottage_analysis.preprocessing import find_frames\n",
    "from cottage_analysis.imaging.common import find_frames as find_img_frames\n",
    "from cottage_analysis.filepath import generate_filepaths\n",
    "from cottage_analysis.imaging.common import imaging_loggers_formatting as format_loggers\n",
    "from cottage_analysis.preprocessing import synchronisation\n",
    "from cottage_analysis.analysis import (\n",
    "    find_depth_neurons,\n",
    "    fit_gaussian_blob,\n",
    "    common_utils,\n",
    ")\n",
    "from cottage_analysis.stimulus_structure import spheres_tube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example session\n",
    "project = \"hey2_3d-vision_foodres_20220101\"\n",
    "mouse = \"PZAH8.2f\"\n",
    "session = \"S20230126\"\n",
    "RECORDING = \"R144331_SpheresPermTubeReward\"\n",
    "protocol = \"SpheresPermTubeReward\"\n",
    "MESSAGES = \"harpmessage.bin\"\n",
    "flexilims_session = flz.get_flexilims_session(project_id=project)\n",
    "# all_protocol_recording_entries = generate_filepaths.get_all_recording_entries(project=project,\n",
    "#                                                                               mouse=mouse,\n",
    "#                                                                               session=session,\n",
    "#                                                                               protocol=protocol,\n",
    "#                                                                               flexilims_session=flexilims_session)\n",
    "\n",
    "# # DO NOT RUN THIS FUNCTION (TAKES 2hrs ish): to find monitor frames from photodiode signal\n",
    "# find_monitor_frames(project=project,\n",
    "#                     mouse=mouse,\n",
    "#                     session=session,\n",
    "#                     protocol=protocol,\n",
    "#                     all_protocol_recording_entries=None,\n",
    "#                     irecording=None,\n",
    "#                     flexilims_session=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synchronisation dataframes\n",
    "vs_df = synchronisation.generate_vs_df(\n",
    "    project=project, mouse=mouse, session=session, protocol=protocol, irecording=0\n",
    ")\n",
    "trials_df, imaging_df = synchronisation.generate_trials_df(\n",
    "    project=project,\n",
    "    mouse=mouse,\n",
    "    session=session,\n",
    "    protocol=protocol,\n",
    "    vs_df=vs_df,\n",
    "    irecording=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find depth neurons and fit preferred depth\n",
    "neurons_df = find_depth_neurons.find_depth_neurons(\n",
    "    project=project,\n",
    "    mouse=mouse,\n",
    "    session=session,\n",
    "    protocol=\"SpheresPermTubeReward\",\n",
    "    rs_thr=0.2,\n",
    ")\n",
    "\n",
    "neurons_df = find_depth_neurons.fit_preferred_depth(\n",
    "    project=project,\n",
    "    mouse=mouse,\n",
    "    session=session,\n",
    "    protocol=\"SpheresPermTubeReward\",\n",
    "    depth_min=0.02,\n",
    "    depth_max=20,\n",
    "    batch_num=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gaussian blob to neuronal activity (THIS WILL ALSO TAKE QUITE LONG! SO STOP EARLIER AND CHECK A FEW CELLS)\n",
    "neurons_df = fit_gaussian_blob.fit_gaussian_blob(\n",
    "    project=project,\n",
    "    mouse=mouse,\n",
    "    session=session,\n",
    "    protocol=\"SpheresPermTubeReward\",\n",
    "    rs_thr=0.01,\n",
    "    param_range={\"rs_min\": 0.005, \"rs_max\": 5, \"of_min\": 0.03, \"of_max\": 3000},\n",
    "    batch_num=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate sphere stimuli\n",
    "def regenerate_stimuli(project, mouse, session, protocol):\n",
    "    def regenerate_stimuli_each_recording(\n",
    "        project,\n",
    "        mouse,\n",
    "        session,\n",
    "        protocols,\n",
    "        protocol,\n",
    "        irecording,\n",
    "        nrecordings,\n",
    "    ):\n",
    "        (\n",
    "            rawdata_folder,\n",
    "            protocol_folder,\n",
    "            _,\n",
    "            _,\n",
    "            _,\n",
    "        ) = generate_filepaths.generate_file_folders(\n",
    "            project=project,\n",
    "            mouse=mouse,\n",
    "            session=session,\n",
    "            protocol=protocol,\n",
    "            all_protocol_recording_entries=None,\n",
    "            recording_no=0,\n",
    "        )\n",
    "\n",
    "        param_log = pd.read_csv(rawdata_folder / \"NewParams.csv\")\n",
    "        param_log = param_log.rename(columns={\"Radius\": \"Depth\"})\n",
    "\n",
    "        with open(protocol_folder / \"sync/imaging_df.pickle\", \"rb\") as handle:\n",
    "            imaging_df = pickle.load(handle)\n",
    "        with open(protocol_folder / \"sync/vs_df.pickle\", \"rb\") as handle:\n",
    "            vs_df = pickle.load(handle)\n",
    "        with open(protocol_folder / \"sync/trials_df.pickle\", \"rb\") as handle:\n",
    "            trials_df = pickle.load(handle)\n",
    "        output = spheres_tube.regenerate_frames(\n",
    "            frame_times=imaging_df[\n",
    "                \"harptime_imaging_trigger\"\n",
    "            ].values,  # using imaging frames as the list of timepoints to reconstruct stimuli\n",
    "            trials_df=trials_df,\n",
    "            vs_df=vs_df,\n",
    "            param_logger=param_log,\n",
    "            time_column=\"HarpTime\",\n",
    "            resolution=1,\n",
    "            sphere_size=10,\n",
    "            azimuth_limits=(-120, 120),\n",
    "            elevation_limits=(-40, 40),\n",
    "            verbose=True,\n",
    "            output_datatype=\"int16\",\n",
    "            output=None,\n",
    "        )\n",
    "\n",
    "        np.save(protocol_folder / \"stimuli.npy\", output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    outputs = []\n",
    "    output = common_utils.loop_through_recordings(\n",
    "        project=project,\n",
    "        mouse=mouse,\n",
    "        session=session,\n",
    "        protocol=protocol,\n",
    "        func=regenerate_stimuli_each_recording,\n",
    "    )\n",
    "    outputs.append(output)\n",
    "    outputs = np.stack(outputs)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "outputs = regenerate_stimuli(project, mouse, session, protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.load(protocol_folder / \"stimuli.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iroi = 3\n",
    "\n",
    "reconstructed_frames = outputs[0]\n",
    "frame_times = imaging_df[\"harptime_imaging_trigger\"].values\n",
    "frame_rate = 15\n",
    "delays = np.array([-1, 0, 1])\n",
    "spk_per_frame = np.stack(imaging_df[\"dffs\"].values)[:, iroi]\n",
    "verbose = True\n",
    "\n",
    "\"\"\"Spike triggered average of reconstructed frames by depth\n",
    "\n",
    "Delays, in second, are delay applied to the stimulus sequence. If delay is -100,\n",
    "that means that spikes were triggered by stimulus 100ms before them.\n",
    "\n",
    "Args:\n",
    "    trials_df (pd.DataFrame): stimulus structure with each row as a trial.\n",
    "    reconstructed_frames (np.array): n frames x n elev x n azim binary array of\n",
    "                                        stimuli\n",
    "    frame_times (np.array): time of each frame, same unit as corridor_df.start_time\n",
    "    frame_rate (float): frame rate to calculate delays. 144 for monitor frames, 15 for imaging frames.\n",
    "    delays (np.array): array of delays in seconds\n",
    "    spk_per_frame (np.array): spike for each frame, use to weight average. If None\n",
    "                                will do simple average\n",
    "    verbose (bool): print progress\n",
    "\n",
    "Returns:\n",
    "    sta (np.array): n depth x n delay x n elev x n azim weighted average\n",
    "    nspkes (np.array): n depth vector of number of spikes\n",
    "    depths (np.array): ordered depths corresponding to first sta dimension\n",
    "    delays (np.array): ordered delays corresponding to second sta dimension\n",
    "\"\"\"\n",
    "if delays is None:\n",
    "    delays = [0]\n",
    "if spk_per_frame is None:\n",
    "    spk_per_frame = np.ones(reconstructed_frames.shape[0])\n",
    "\n",
    "depths = np.sort(trials_df.depth.unique())\n",
    "full_sta = np.zeros((len(depths), len(delays), *reconstructed_frames.shape[1:]))\n",
    "nspks = np.zeros(len(depths))\n",
    "\n",
    "for idepth, depth in enumerate(depths):\n",
    "    if verbose:\n",
    "        print(f\"... doing depth {depth*100} cm\")\n",
    "    depth_df = trials_df[trials_df.depth == depth]\n",
    "    # find frames at this depth\n",
    "    # starts = depth_df.imaging_frame_stim_start.values\n",
    "    # ends = depth_df.imaging_frame_stim_stop.values\n",
    "    starts = frame_times.searchsorted(depth_df.harptime_stim_start)\n",
    "    ends = frame_times.searchsorted(depth_df.harptime_stim_stop)\n",
    "    ends = ends[: len(starts)]\n",
    "    frame_index = np.hstack([np.arange(s, e, dtype=int) for s, e in zip(starts, ends)])\n",
    "    # keep non-shifted spikes for all delay\n",
    "    # do it like that to look for valid frames only once\n",
    "    spk_per_frame_at_depth = spk_per_frame[frame_index]\n",
    "    nspks[idepth] = np.sum(spk_per_frame_at_depth)\n",
    "    valid_frames = spk_per_frame_at_depth != 0\n",
    "    for idelay, delay in enumerate(delays):\n",
    "        if verbose:\n",
    "            print(f\"... ... doing delay {delay * 1000} ms\")\n",
    "        shift = int(delay * frame_rate)\n",
    "        # shift the stim\n",
    "        shifted_frames = np.clip(frame_index[valid_frames] + shift, 0, len(frame_times))\n",
    "        stims = reconstructed_frames[shifted_frames].reshape(len(shifted_frames), -1)\n",
    "        sta = np.dot(stims.T, spk_per_frame_at_depth[valid_frames])\n",
    "        sta = sta.reshape(reconstructed_frames.shape[1:])\n",
    "        full_sta[idepth, idelay] = sta\n",
    "        # !! Needs to add normalized STA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iroi = 3\n",
    "\n",
    "reconstructed_frames = outputs[0]\n",
    "frame_times = imaging_df[\"harptime_imaging_trigger\"].values\n",
    "frame_rate = 15\n",
    "delays = np.array([-1, 0, 1])\n",
    "spk_per_frame = np.stack(imaging_df[\"dffs\"].values)[:, iroi]\n",
    "verbose = True\n",
    "\n",
    "\"\"\"Spike triggered average of reconstructed frames by depth\n",
    "\n",
    "Delays, in second, are delay applied to the stimulus sequence. If delay is -100,\n",
    "that means that spikes were triggered by stimulus 100ms before them.\n",
    "\n",
    "Args:\n",
    "    trials_df (pd.DataFrame): stimulus structure with each row as a trial.\n",
    "    reconstructed_frames (np.array): n frames x n elev x n azim binary array of\n",
    "                                        stimuli\n",
    "    frame_times (np.array): time of each frame, same unit as corridor_df.start_time\n",
    "    frame_rate (float): frame rate to calculate delays. 144 for monitor frames, 15 for imaging frames.\n",
    "    delays (np.array): array of delays in seconds\n",
    "    spk_per_frame (np.array): spike for each frame, use to weight average. If None\n",
    "                                will do simple average\n",
    "    verbose (bool): print progress\n",
    "\n",
    "Returns:\n",
    "    sta (np.array): n depth x n delay x n elev x n azim weighted average\n",
    "    nspkes (np.array): n depth vector of number of spikes\n",
    "    depths (np.array): ordered depths corresponding to first sta dimension\n",
    "    delays (np.array): ordered delays corresponding to second sta dimension\n",
    "\"\"\"\n",
    "if delays is None:\n",
    "    delays = [0]\n",
    "if spk_per_frame is None:\n",
    "    spk_per_frame = np.ones(reconstructed_frames.shape[0])\n",
    "\n",
    "depths = np.sort(trials_df.depth.unique())\n",
    "full_sta = np.zeros((len(depths), len(delays), *reconstructed_frames.shape[1:]))\n",
    "nspks = np.zeros(len(depths))\n",
    "\n",
    "for idepth, depth in enumerate(depths):\n",
    "    if verbose:\n",
    "        print(f\"... doing depth {depth*100} cm\")\n",
    "    depth_df = trials_df[trials_df.depth == depth]\n",
    "    # find frames at this depth\n",
    "    # starts = depth_df.imaging_frame_stim_start.values\n",
    "    # ends = depth_df.imaging_frame_stim_stop.values\n",
    "    starts = frame_times.searchsorted(depth_df.harptime_stim_start)\n",
    "    ends = frame_times.searchsorted(depth_df.harptime_stim_stop)\n",
    "    ends = ends[: len(starts)]\n",
    "    frame_index = np.hstack([np.arange(s, e, dtype=int) for s, e in zip(starts, ends)])\n",
    "    # keep non-shifted spikes for all delay\n",
    "    # do it like that to look for valid frames only once\n",
    "    spk_per_frame_at_depth = spk_per_frame[frame_index]\n",
    "    nspks[idepth] = np.sum(spk_per_frame_at_depth)\n",
    "    valid_frames = spk_per_frame_at_depth != 0\n",
    "    for idelay, delay in enumerate(delays):\n",
    "        if verbose:\n",
    "            print(f\"... ... doing delay {delay * 1000} ms\")\n",
    "        shift = int(delay * frame_rate)\n",
    "        # shift the stim\n",
    "        shifted_frames = np.clip(frame_index[valid_frames] + shift, 0, len(frame_times))\n",
    "        stims = reconstructed_frames[shifted_frames].reshape(len(shifted_frames), -1)\n",
    "        sta = np.dot(stims.T, spk_per_frame_at_depth[valid_frames])\n",
    "        sta = sta.reshape(reconstructed_frames.shape[1:])\n",
    "        full_sta[idepth, idelay] = sta\n",
    "        # !! Needs to add normalized STA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cottage_analysis.analysis import sta\n",
    "\n",
    "outputs = sta.regenerate_stimuli(project, mouse, session, protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
