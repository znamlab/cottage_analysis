{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing and synchronizing ephys data: an example notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this notebook is to be able to take all the output files that are generated by the ephys setup and Ronan cottage and synchronizing all of them to the same clock.\n",
    "\n",
    "We are using session S20230323 from BRAC4779.2a [HELMET], the first session we recorded. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running list of things ot improve on\n",
    "\n",
    "- As a small note, we have to re-write the bonsai workflow to record the cameras in the arena in a convincing way, so that it inherits the name from the stimulus workflow ideally, like in Yiran's case. Work on that. \n",
    "- The outputs should all go to the same recording folder if they're part of the same recording. Like in Yiran's case. \n",
    "- We want to save the raw output from the chip, so we will have to find a way to remap it later, I guess. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cottage_analysis.io_module.onix as onix\n",
    "import cottage_analysis.io_module.harp as harp\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "session = Path('/camp/lab/znamenskiyp/data/instruments/raw_data/projects/blota_onix_pilote/BRAC7449.2a/S20230323')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which files were outputted this time?\n",
    "\n",
    "- Three different folders and some loose files \n",
    "    - Outputs of the AcquireEphys\n",
    "    - Outputs of stimulus\n",
    "    - Outputs of HF cameras\n",
    "    - Outputs of FM cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys = session / 'R115806'\n",
    "stimulus = session / 'R115817_SpheresPermTubeReward'\n",
    "headfixed_cam = session / 'R115821_BRAC7449.2a'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the ephys outputs (rhd2164)\n",
    "\n",
    "Ephys outputs start with rhd2164, which is the intan digital electrophysiology interface chip on the headstage. There are three files created, one is aux, one is clock, one is ephys and one is first_time. \n",
    "\n",
    "Antonin wrote a function which takes them all together and makes a memmap object with them, so that they can be easily accessed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_ephys = onix.load_rhd2164(ephys)\n",
    "processed_ephys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's attempt to read the ephys outputs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import os\n",
    "import spikeinterface.extractors as se\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import spikeinterface as si\n",
    "\n",
    "num_channels = 64\n",
    "sampling_frequency = 30000\n",
    "gain_to_uV = 0.195\n",
    "offset_to_uV = -2**15*gain_to_uV\n",
    "dtype=\"uint16\"#This could be sensitive: our chip writes in uint16, had to change to int16 for kilosort (?)\n",
    "time_axis = 0\n",
    "\n",
    "path_to_openephys = '/camp/lab/znamenskiyp/data/instruments/raw_data/projects/blota_onix_pilote/BRAC7449.2a/S20230323/R115806/rhd2164-ephys_2023-03-23T11_58_06.raw'\n",
    "\n",
    "recording = si.read_binary(path_to_openephys, num_chan=num_channels, sampling_frequency=sampling_frequency,\n",
    "                            dtype=dtype, gain_to_uV=gain_to_uV, offset_to_uV=offset_to_uV,\n",
    "                            time_axis=time_axis)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import spikeinterface.widgets as sw\n",
    "\n",
    "#trace_snippet = recording.get_traces(start_frame=int(fs*0), end_frame=int(fs*2))\n",
    "#print('Traces shape:', trace_snippet.shape)\n",
    "\n",
    "import scipy.signal\n",
    "from spikeinterface.preprocessing import (bandpass_filter, notch_filter, common_reference,\n",
    "                                          remove_artifacts, preprocesser_dict)\n",
    "recording_bp = bandpass_filter(recording, freq_min=200, freq_max=10000)\n",
    "\n",
    "recording_cmr = common_reference(recording_bp, reference='global', operator='median')\n",
    "\n",
    "\n",
    "channel_ids = range(30, 40)\n",
    "channel_ids\n",
    "\n",
    "w_ts = sw.plot_timeseries(recording_cmr, channel_ids=channel_ids, time_range=(2000.8, 2001), return_scaled=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading lighthouse data (ts4231)\n",
    "\n",
    "Three different lighthouse-generated files, one per diode. ts4231 is the name of the photodiode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_photodiode = onix.load_ts4231(ephys)\n",
    "processed_photodiode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize = (9, 7))\n",
    "\n",
    "fig.suptitle('Value of x for the three photodiodes in the headstage')\n",
    "axs[0].plot(processed_photodiode[1]['clock'], processed_photodiode[1]['x'])\n",
    "axs[1].plot(processed_photodiode[2]['clock'], processed_photodiode[2]['x'])\n",
    "axs[2].plot(processed_photodiode[3]['clock'], processed_photodiode[3]['x'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading IMU data (bno055)\n",
    "\n",
    "We have nothing to load the IMU data. Should I write it? Wrote it on onix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_bno = onix.load_bno055(ephys)\n",
    "processed_bno.keys()\n",
    "\n",
    "quaternion = processed_bno['quaternion']\n",
    "quaternion = quaternion/2**14\n",
    "linear = processed_bno['linear']\n",
    "linear = linear / 100\n",
    "euler = processed_bno['euler']\n",
    "euler = euler / 16\n",
    "gravity = processed_bno['gravity']\n",
    "gravity = gravity / 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how they look. Wrong, they look wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = len(linear[:,1])/100/60\n",
    "\n",
    "print(f'The recording was {minutes} s in length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(9, 9))\n",
    "\n",
    "fig.suptitle('BNO055 (timestamps 20000-201000)')\n",
    "\n",
    "timeslice=range(170000, 170100)\n",
    "\n",
    "axs[0, 0].plot(quaternion[timeslice, 3])\n",
    "axs[0, 0].plot(quaternion[timeslice, 0])\n",
    "axs[0, 0].plot(quaternion[timeslice, 1])\n",
    "axs[0, 0].plot(quaternion[timeslice, 2])\n",
    "axs[0, 0].set_title('Quaternion')\n",
    "\n",
    "axs[0, 1].plot(linear[timeslice, 0])\n",
    "axs[0, 1].plot(linear[timeslice, 1])\n",
    "axs[0, 1].plot(linear[timeslice, 2])\n",
    "axs[0, 1].set_title('Linear acceleration')\n",
    "\n",
    "axs[1, 1].plot(euler[timeslice, 0])\n",
    "axs[1, 1].plot(euler[timeslice, 1])\n",
    "axs[1, 1].plot(euler[timeslice, 2])\n",
    "axs[1, 1].set_title('Euler Vector')\n",
    "\n",
    "axs[1, 0].plot(gravity[timeslice, 0])\n",
    "axs[1, 0].plot(gravity[timeslice, 1])\n",
    "axs[1, 0].plot(gravity[timeslice, 2])\n",
    "axs[1, 0].set_title('Gravity vector')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extract the heading from this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import atan2\n",
    "\n",
    "fq0=quaternion[:,0]\n",
    "fq1=quaternion[:,1]\n",
    "fq2=quaternion[:,2]\n",
    "fq3=quaternion[:,3]\n",
    "heading = np.zeros(len(fq0))\n",
    "#heading[sample] = [atan2((2*(quaternion[0]*quaternion[3]+quaternion[1]*quaternion[2])), (1-2*(quaternion[2]**2+quaternion[3]**2))) for sample in quaternion[0]]\n",
    "\n",
    "for i in range(len(fq0)):\n",
    "    q0, q1, q2, q3 = fq0[i], fq1[i], fq2[i], fq3[i]\n",
    "    heading[i]=atan2((2*(q0*q3+q1*q2)), (1-2*(q2**2+q3**2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(heading[timeslice])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the stimulus logs and synchronizing them to the ephys clock"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the freely moving cameras and synchronizing them to the ephys clock"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the head-fixed cameras and synchronizing them to the ephys clock"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cottage_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "99c5ab3b34a62a7741b597fad5e753313eb10ed9c721f639f5c87868832eb072"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
